[
  {
    "objectID": "contributions.html",
    "href": "contributions.html",
    "title": "Contributions",
    "section": "",
    "text": "Adnan Baig | BSc in Economics\nAnna Jin | BSc in Economics\nHailey Stevens | BA in History"
  },
  {
    "objectID": "contributions.html#team-members",
    "href": "contributions.html#team-members",
    "title": "Contributions",
    "section": "",
    "text": "Adnan Baig | BSc in Economics\nAnna Jin | BSc in Economics\nHailey Stevens | BA in History"
  },
  {
    "objectID": "contributions.html#guidance",
    "href": "contributions.html#guidance",
    "title": "Contributions",
    "section": "Guidance",
    "text": "Guidance\n\nAlexander Soldatkin\nJon Cardoso-Silva"
  },
  {
    "objectID": "visualisations.html#introduction",
    "href": "visualisations.html#introduction",
    "title": "Mobilisation Insights",
    "section": "Introduction",
    "text": "Introduction\nThe initial analysis corroborated what we knew about the GME event, with visualisations clearly delineating the saga and linking stock fluctuations to real-time events effectively.\nOur next goal was to dive deeper into the phenomenon of how a dispersed group mobilised for change. Based on prior literature, we aimed to understand how they engaged in ‘connective action’ (Bennet, 2012), where the subreddit engages in collective action emerging from the use of digital media. Importantly, this refers to (i) decentralised and personalised participation, (ii) where a narrative is pursued against the establishment. We believe the incident meets these criteria.\nThis analysis, new to us, sought to identify trends and themes that explained the ‘why’ and ‘how’ of their collective action, without a predetermined path for investigation."
  },
  {
    "objectID": "visualisations.html#word-cloud-analysis",
    "href": "visualisations.html#word-cloud-analysis",
    "title": "Mobilisation Insights",
    "section": "Word Cloud Analysis",
    "text": "Word Cloud Analysis\nWord clouds offered an immediate visualisation of key terms, guiding our deeper investigation towards more substantive and actionable insights.\n  \n\nJanuary Word Cloud\nJanuary: The term “buy” stands out prominently, along with “stock” and “GME,” signalling a strong buying sentiment and interest in GME stock. This suggests an alignment with the initial surge in GME’s share price, indicating a period of heightened investor enthusiasm.\n\n\nFebruary Word Cloud\nFebruary: Words like “hold” and “now” emerge as dominant, reflecting ongoing interest in GME. This seems to support the narrative of investors holding onto their shares amidst market fluctuations, showcasing a collective resolve.\n\n\nMarch Word Cloud\nMarch: “Price” and “share” continue to be significant, complemented by the appearance of “million” and “sell.” This shift might denote discussions around profit-taking or evaluating the stock’s worth following its earlier rally, pointing to a more cautious or strategic approach by the community.\nThese insights are analogous to those speculated throughout our interactive timeline.\n\n\nIssues\nWhile word clouds provide an intuitive and visually appealing way to explore textual data, their reliance on the frequency of individual words can lead to oversimplification, especially with complex topics like the GME saga. This method overlooks the context in which words are used together, missing crucial nuances and the relationships between terms. Therefore, we felt it necessary to augment these word clouds with more advanced text analysis tools to grasp the subtleties and deeper insights of such discussions."
  },
  {
    "objectID": "visualisations.html#lda-analysis",
    "href": "visualisations.html#lda-analysis",
    "title": "Mobilisation Insights",
    "section": "LDA Analysis",
    "text": "LDA Analysis\nLatent Dirichlet Allocation (LDA) is a type of statistical model used for discovering the abstract “topics” that occur in a large volume of data.\nLDA is an unsupervised learning technique, which means it doesn’t require pre-labelled training data. This makes it suitable for exploratory data analysis where the themes or topics are not known a priori.\nHowever, the “topics” unearthed through LDA, being distributions of words, may not always encapsulate coherent or meaningful themes without careful interpretation. Also, LDA does not take into account the evolution of topics over time, which is relevant for this dynamic dataset.\nRegardless, the LDA visualisation offered intriguing insights, revealing underlying patterns and themes that were not immediately apparent.\n \n \nTerms like “moon,” “GME,” and “AMC” signal optimism towards rising stock prices, a perspective not captured in the word clouds. Similarly, “squeeze” and “hold” hint at trading strategy discussions, likely around short squeezes or maintaining positions through volatility.\n \nAdjusting the LDA model’s parameters, including the number of topics and iterations, enhanced our coherence score. In a refined analysis with five topics, the model’s output was as follows:\n\nTopic 1: Focused on actions related to stocks, particularly “buying” and “removing” with a strong focus on GME and AMC, indicating investment strategy discussions.\n\n\nTopic 4: Centred on the “short squeeze” narrative and optimism, with terms like “moon” and “squeeze” pointing to discussions on stock value surges.\n\n\nTopic 5: Related to trading timing, with advice on “buying dips” or “holding shares,” indicated by terms like “sell,” “tomorrow,” and “don’t stop”.\n\n \nUsing adjusted parameters, such as for three topics, the model’s output was as follows:\n\nTopic 1: Pertains to professional financial analysis, discussing company earnings, growth, and larger economic elements like policy impacts and sector advancements; e.g. “quarter,” “growth,” “sales,” and “earnings”.\n\n\nTopic 2: Reflects informal trading discussions on Reddit, intertwined with celebrity influence and cryptocurrency, emphasising buy/sell dynamics; e.g. “papa”, “musk”.\n\n\nTopic 3: Showcases individual financial narratives and community advice, marked by a blend of investment strategy talk and forum slang, such as “portfolio,” “money”, and “savings”.\n\n \n\nInsights\nLDA’s insights have been pivotal in unravelling the GME saga by showing how individual actors found common ground and formed a collective momentum, crucial aspects of connective action. The model revealed an alignment of interests and strategies, as terms like “moon,” “squeeze,” and “hold” reflect a shared optimism and a collective approach to trading.\nThe LDA model pinpointed key phrases like “moon,” “squeeze,” and “hold” as unifiers within the GME community, illustrating how these terms helped coordinate individual efforts into collective action. This analysis provided concrete insights into the group’s strategy, demonstrating the dynamics of connective action where digital platforms were used to align individual actions against market norms."
  },
  {
    "objectID": "visualisations.html#sentiment-analysis",
    "href": "visualisations.html#sentiment-analysis",
    "title": "Mobilisation Insights",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nSentiment analysis, in the context of stock market behaviour, serves as a powerful tool to gauge the mood and opinions of a wide array of market participants.\nBy quantifying emotions and views expressed across social media platforms, news articles, and other mediums, sentiment analysis provides an overview of the collective attitude toward a particular stock or the market in general.\nIt is crucial to note that the insights drawn do not imply causation.\n \n\n \nThe sentiment analysis plot for GME stock illustrates several points of interest:\n\nThere is a visible correlation where increases in sentiment scores often coincide with or precede rises in GME’s stock price.\n\n\nSharp spikes in sentiment appear to foreshadow significant upticks in stock price, suggesting that heightened positive sentiment could influence trading behaviour.\n\n\nThe sentiment’s role is not uniform; it varies, sometimes acting as a leading indicator and other times trailing the stock price changes.\n\nThese observations underscore the interconnectedness of sentiment and stock prices, although the exact nature of this relationship remains complex and non-causal."
  },
  {
    "objectID": "collection.html",
    "href": "collection.html",
    "title": "Data Collection",
    "section": "",
    "text": "Reddit API Limitations: The inability to filter posts by date with the Reddit API hampers historical data collection.\nPushshift API Access Restrictions: Changes in the Pushshift API’s terms of use restrict its availability for research, limiting access to historical subreddit data.\nScraping Date-Specific Data: The need to find alternative methods to bypass the Reddit API’s date filtering limitations complicates data collection.\nWeb Scraping Tool Limitations: Using Selenium for scraping reveals a cap on data volume, with a maximum of 1000 recent posts being retrievable at a time.\nAPI Access Challenges: Failed attempts to use another’s Pushshift API access highlight the difficulties in obtaining necessary permissions for data access.\nData Format Navigation: Requesting a CSV version of Reddit API data points to the challenges of managing and utilizing the provided data formats efficiently.",
    "crumbs": [
      "Data Collection"
    ]
  },
  {
    "objectID": "collection.html#rwallstreetbets-posts",
    "href": "collection.html#rwallstreetbets-posts",
    "title": "Data Collection",
    "section": "",
    "text": "Reddit API Limitations: The inability to filter posts by date with the Reddit API hampers historical data collection.\nPushshift API Access Restrictions: Changes in the Pushshift API’s terms of use restrict its availability for research, limiting access to historical subreddit data.\nScraping Date-Specific Data: The need to find alternative methods to bypass the Reddit API’s date filtering limitations complicates data collection.\nWeb Scraping Tool Limitations: Using Selenium for scraping reveals a cap on data volume, with a maximum of 1000 recent posts being retrievable at a time.\nAPI Access Challenges: Failed attempts to use another’s Pushshift API access highlight the difficulties in obtaining necessary permissions for data access.\nData Format Navigation: Requesting a CSV version of Reddit API data points to the challenges of managing and utilizing the provided data formats efficiently.",
    "crumbs": [
      "Data Collection"
    ]
  },
  {
    "objectID": "collection.html#gamestop-stock-prices",
    "href": "collection.html#gamestop-stock-prices",
    "title": "Data Collection",
    "section": "GameStop Stock Prices",
    "text": "GameStop Stock Prices\n\nCollection Process\n\n\n\nChallenges Faced\n\nAPI Key Registration: Obtaining an API key requires registration, which may involve sharing personal information and adhering to specific use cases.\nRate Limits and Quotas: Alpha Vantage imposes rate limits that can slow the data collection process, a significant consideration for large datasets.",
    "crumbs": [
      "Data Collection"
    ]
  },
  {
    "objectID": "data_overview.html#interactive-plot",
    "href": "data_overview.html#interactive-plot",
    "title": "Data Overview",
    "section": "Interactive Plot",
    "text": "Interactive Plot",
    "crumbs": [
      "Data Overview"
    ]
  },
  {
    "objectID": "data_overview.html#interactive-timeline",
    "href": "data_overview.html#interactive-timeline",
    "title": "Data Overview",
    "section": "Interactive Timeline",
    "text": "Interactive Timeline",
    "crumbs": [
      "Data Overview"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dabbling in Data",
    "section": "",
    "text": "2020-21 GameStop Short Squeeze: an analysis of the profound impact of social meedia communities on the price of GameStop stock."
  },
  {
    "objectID": "index.html#project-overview",
    "href": "index.html#project-overview",
    "title": "Dabbling in Data",
    "section": "Project Overview",
    "text": "Project Overview\nWelcome to Dabbling in Data, a project which delves into the GameStop (GME) short squeeze phenomenon. Our primary objective is to shed light on the causation and degree of influence the Reddit community, r/wallstreetbets, had on the stock price of GameStop. We conducted an analysis of GME stock data in relation to r/wallstreetbets posts, over the period December 2020 to March 2021."
  },
  {
    "objectID": "index.html#our-motivation",
    "href": "index.html#our-motivation",
    "title": "Dabbling in Data",
    "section": "Our Motivation",
    "text": "Our Motivation\nOur project stems from a fascination with this event and its disruption to traditional financial norms, its empowerment of online communities, and its ensuing impact on regulation. Through our analysis, we aim to reveal the role of online communities on stock market behaviour."
  },
  {
    "objectID": "index.html#contextualising-our-project",
    "href": "index.html#contextualising-our-project",
    "title": "Dabbling in Data",
    "section": "Contextualising Our Project",
    "text": "Contextualising Our Project\nThe GameStop short squeeze in early 2021 saw a remarkable surge in the stock price of GameStop (GME). This surge was orchestrated by retail investors, particularly through the Reddit community r/wallstreetbets. As these investors bought GME shares en masse, it forced hedge funds and institutional investors, who had bet against the stock, to cover their positions, causing GME’s price to skyrocket."
  },
  {
    "objectID": "conclusions.html#mobilisation-insights",
    "href": "conclusions.html#mobilisation-insights",
    "title": "Conclusions",
    "section": "Mobilisation Insights",
    "text": "Mobilisation Insights\n\nWord Clouds:\nThey served as our initial compass, highlighting prevalent terms and granting us a bird’s-eye view of the dominant discourse. While informative, word clouds merely scratch the surface, offering a glimpse rather than a deep dive.\n\n\nLDA Analysis:\nAdvancing to LDA provided a more structured understanding of the conversations taking place. It revealed clusters of discussion around topics like “GME,” “squeeze,” and “hold,” which reflect facets of the community’s collective action. However, the true significance of these topics requires context that goes beyond their frequency and distribution.\n\n\nSentiment Analysis:\nOur sentiment analysis painted a narrative of rising and falling emotional tides within the GME dialogue. Peaks in sentiment seemed to walk hand-in-hand with stock price movements, but this visual waltz should not be mistaken for a causal relationship. Multiple unseen variables could be at play, and sentiment is but one actor on a crowded stage.\nUltimately, with the current insights, we can surmise interesting patterns and correlations across the data. Yet, we acknowledge that these are not definitive conclusions."
  },
  {
    "objectID": "conclusions.html#further-analysis",
    "href": "conclusions.html#further-analysis",
    "title": "Conclusions",
    "section": "Further Analysis",
    "text": "Further Analysis\nWhile the word cloud, LDA, and sentiment analysis have yielded valuable insights into the GME saga, providing a glimpse into the collective mindset and topics of discussion, there’s room for deeper exploration. If, for example, we had the ability to track individual user behaviour over time, access more granular transaction data, and monitor comment threads in real-time, we could pursue a more comprehensive analysis.\n \nBy implementing these, and approaching the data from different angles such as through time-series analysis, or machine learning models we could potentially:\n\nUnderstanding the speed and magnitude of the market’s reaction to real-time events.\n\n\nIdentify the causative influence, if any, of sentiment on price movements.\n\n\nForecast future stock price trends based on current sentiment data.\n\nAnd thus:\n\nUnderstand the predictive power of sentiment over stock prices.\n\n\nAssess the degree to which sentiment reflects broader market trends or specific events.\n\n\nProvide actionable intelligence for traders and market analysts, enhancing decision-making processes.\n\n \nWith access to longitudinal data, user-level interactions, and the capability to parse the subtleties of sentiment in real-time, we could potentially unravel the causative threads of market movements."
  },
  {
    "objectID": "cleaning.html",
    "href": "cleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "Formatting: Converting ‘score’ and ‘num_comments’ fields from their original format to integers for quantitative analysis presents a fundamental data type consistency challenge.\nAlignment: Formatting the ‘date’ column to ‘datetime64’ to ensure compatibility and precise alignment with GameStop (GME) stock price data for time series analysis.\nAggregation: Using the groupby method to aggregate posts by date requires careful handling to ensure accurate summarization of data points, like total posts, average scores, or comments per day.\nCreating Dataframe: The overall process of transforming raw subreddit data into a cleaned and structured dataframe ready for analysis involves several preprocessing steps, including handling missing values, removing duplicates, and standardizing data formats.",
    "crumbs": [
      "Data Cleaning"
    ]
  },
  {
    "objectID": "cleaning.html#rwallstreetbets-posts",
    "href": "cleaning.html#rwallstreetbets-posts",
    "title": "Data Cleaning",
    "section": "",
    "text": "Formatting: Converting ‘score’ and ‘num_comments’ fields from their original format to integers for quantitative analysis presents a fundamental data type consistency challenge.\nAlignment: Formatting the ‘date’ column to ‘datetime64’ to ensure compatibility and precise alignment with GameStop (GME) stock price data for time series analysis.\nAggregation: Using the groupby method to aggregate posts by date requires careful handling to ensure accurate summarization of data points, like total posts, average scores, or comments per day.\nCreating Dataframe: The overall process of transforming raw subreddit data into a cleaned and structured dataframe ready for analysis involves several preprocessing steps, including handling missing values, removing duplicates, and standardizing data formats.",
    "crumbs": [
      "Data Cleaning"
    ]
  },
  {
    "objectID": "cleaning.html#gamestop-stock-prices",
    "href": "cleaning.html#gamestop-stock-prices",
    "title": "Data Cleaning",
    "section": "GameStop Stock Prices",
    "text": "GameStop Stock Prices\n\nCleaning Process\n\n\n\nChallenges Faced\nCreating Dataframe: The overarching challenge of transforming the raw API data into a cleaned dataframe involves multiple sub-tasks.\n\nEnsuring data consistency and accuracy after type conversion.\nHandling any missing or anomalous data points that could skew analysis.\nStructuring the data in a way that aligns with analytical goals, ensuring it’s ready for analysis or visualization.",
    "crumbs": [
      "Data Cleaning"
    ]
  }
]