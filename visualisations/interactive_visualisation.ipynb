{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import json\n","import requests\n","\n","import pandas as pd\n","import mplfinance as mpf\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","metadata":{},"source":["Loading pickled GME stock price dataframe"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Replace this with the path to your pickled file\n","pickle_file_path = '../scraping/gme_daily_transformed_df.pkl'\n","\n","# Load the DataFrame from the pickle file\n","gme_daily_transformed_df = pd.read_pickle(pickle_file_path)"]},{"cell_type":"markdown","metadata":{},"source":["Filtering dataframe to only include dates in the relevant period"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Filtering the DataFrame to include only data from December 2020 to April 2021 and creating a copy\n","gme_jan_apr2021_df = gme_daily_transformed_df[(gme_daily_transformed_df['Date'] >= '2021-01-01') & (gme_daily_transformed_df['Date'] <= '2021-04-01')].copy()"]},{"cell_type":"markdown","metadata":{},"source":["Reading Reddit data from CSV files into a dataframe"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["data1_df = pd.read_csv('../data/reddit_data/Submissions_2021-01_FilteredBySubreddit_GME.csv')\n","data2_df = pd.read_csv('../data/reddit_data/Submissions_2021-02_FilteredBySubreddit_GME.csv')\n","data3_df = pd.read_csv('../data/reddit_data/Submissions_2021-03_FilteredBySubreddit_GME.csv')\n","\n","df_all_reddit_data = pd.concat([data1_df, data2_df, data3_df], axis = 0,\n","                        ignore_index=True)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>version https://git-lfs.github.com/spec/v1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>oid sha256:80f72cf9ea5decc62c2a792c62a7af63cd3...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>size 184615586</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>oid sha256:3ba73203624a3055659d4d4a0752f5a5ab2...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>size 140858469</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>oid sha256:4ffc719a8345dfcc6650e813315221b755f...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          version https://git-lfs.github.com/spec/v1\n","0  oid sha256:80f72cf9ea5decc62c2a792c62a7af63cd3...\n","1                                     size 184615586\n","2  oid sha256:3ba73203624a3055659d4d4a0752f5a5ab2...\n","3                                     size 140858469\n","4  oid sha256:4ffc719a8345dfcc6650e813315221b755f..."]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_all_reddit_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["Processing dataframe"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'num_comments'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'num_comments'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Remove curly brackets from num_comments and score columns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_all_reddit_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_comments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_all_reddit_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_comments\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m])), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m df_all_reddit_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_all_reddit_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m])), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Remove date and time from num_comments and score columns\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'num_comments'"]}],"source":["# Remove curly brackets from num_comments and score columns\n","df_all_reddit_data['num_comments'] = df_all_reddit_data['num_comments'].str.replace('[{}]'.format(''.join(['{}'])), '', regex=True)\n","df_all_reddit_data['score'] = df_all_reddit_data['score'].str.replace('[{}]'.format(''.join(['{}'])), '', regex=True)\n","\n","\n","# Remove date and time from num_comments and score columns\n","df_all_reddit_data['num_comments'] = df_all_reddit_data['num_comments'].str.split(':').str[-1].str.strip()\n","df_all_reddit_data['score'] = df_all_reddit_data['score'].str.split(':').str[-1].str.strip()\n","\n","\n","# Convert num_comments and score columns to integers\n","df_all_reddit_data['num_comments'] = df_all_reddit_data['num_comments'].astype(int)\n","df_all_reddit_data['score'] = df_all_reddit_data['score'].astype(int)\n","\n","\n","df_all_reddit_data['created_at'] = pd.to_datetime(df_all_reddit_data['created_at'])\n","# Extract only the date part\n","df_all_reddit_data['created_at'] = df_all_reddit_data['created_at'].dt.normalize()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>submission_id</th>\n","      <th>redditor_name</th>\n","      <th>created_at</th>\n","      <th>title</th>\n","      <th>text</th>\n","      <th>subreddit</th>\n","      <th>permalink</th>\n","      <th>attachment</th>\n","      <th>flair</th>\n","      <th>score</th>\n","      <th>num_comments</th>\n","      <th>edited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ko124i</td>\n","      <td>[deleted]</td>\n","      <td>2021-01-01</td>\n","      <td>3k - 170k since March (Also, buy LIT!!)</td>\n","      <td>[deleted]</td>\n","      <td>wallstreetbets</td>\n","      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n","      <td>NaN</td>\n","      <td>{'link': 'Gain', 'author': None}</td>\n","      <td>34</td>\n","      <td>14</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ko12uq</td>\n","      <td>[deleted]</td>\n","      <td>2021-01-01</td>\n","      <td>Got out of PLTR calls after learning about IV ...</td>\n","      <td>[deleted]</td>\n","      <td>wallstreetbets</td>\n","      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n","      <td>{'url': 'https://www.reddit.com/gallery/ko12uq'}</td>\n","      <td>{'link': 'Gain', 'author': None}</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ko13df</td>\n","      <td>[deleted]</td>\n","      <td>2021-01-01</td>\n","      <td>Hell of a headline</td>\n","      <td>[deleted]</td>\n","      <td>wallstreetbets</td>\n","      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n","      <td>{'png': 'https://i.redd.it/620igsuk3m861.png'}</td>\n","      <td>{'link': 'Meme', 'author': None}</td>\n","      <td>14</td>\n","      <td>7</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ko13q2</td>\n","      <td>DarkCookie243</td>\n","      <td>2021-01-01</td>\n","      <td>A message from JPow for New Years Eve to all o...</td>\n","      <td>NaN</td>\n","      <td>wallstreetbets</td>\n","      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n","      <td>{'jpg': 'https://i.redd.it/rkb331xu3m861.jpg'}</td>\n","      <td>{'link': 'Meme', 'author': None}</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ko145e</td>\n","      <td>stevenconrad</td>\n","      <td>2021-01-01</td>\n","      <td>GME to 420.69, but only if we make it happen. ...</td>\n","      <td>[removed]</td>\n","      <td>wallstreetbets</td>\n","      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n","      <td>NaN</td>\n","      <td>{'link': 'DD', 'author': None}</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  submission_id  redditor_name created_at  \\\n","0        ko124i      [deleted] 2021-01-01   \n","1        ko12uq      [deleted] 2021-01-01   \n","2        ko13df      [deleted] 2021-01-01   \n","3        ko13q2  DarkCookie243 2021-01-01   \n","4        ko145e   stevenconrad 2021-01-01   \n","\n","                                               title       text  \\\n","0            3k - 170k since March (Also, buy LIT!!)  [deleted]   \n","1  Got out of PLTR calls after learning about IV ...  [deleted]   \n","2                                 Hell of a headline  [deleted]   \n","3  A message from JPow for New Years Eve to all o...        NaN   \n","4  GME to 420.69, but only if we make it happen. ...  [removed]   \n","\n","        subreddit                                          permalink  \\\n","0  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n","1  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n","2  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n","3  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n","4  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n","\n","                                         attachment  \\\n","0                                               NaN   \n","1  {'url': 'https://www.reddit.com/gallery/ko12uq'}   \n","2    {'png': 'https://i.redd.it/620igsuk3m861.png'}   \n","3    {'jpg': 'https://i.redd.it/rkb331xu3m861.jpg'}   \n","4                                               NaN   \n","\n","                              flair  score  num_comments  edited  \n","0  {'link': 'Gain', 'author': None}     34            14   False  \n","1  {'link': 'Gain', 'author': None}      2             0   False  \n","2  {'link': 'Meme', 'author': None}     14             7   False  \n","3  {'link': 'Meme', 'author': None}      4             0   False  \n","4    {'link': 'DD', 'author': None}      9             4   False  "]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["df_all_reddit_data.head()\n"]},{"cell_type":"markdown","metadata":{},"source":["Groupby - keep looking into"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Post_Count</th>\n","      <th>Total_Comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-01-01</td>\n","      <td>589</td>\n","      <td>45186</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-01-02</td>\n","      <td>625</td>\n","      <td>11609</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-01-03</td>\n","      <td>613</td>\n","      <td>25134</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-01-04</td>\n","      <td>1029</td>\n","      <td>55169</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-01-05</td>\n","      <td>965</td>\n","      <td>65804</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>2021-03-28</td>\n","      <td>1178</td>\n","      <td>30131</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>2021-03-29</td>\n","      <td>2065</td>\n","      <td>85797</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>2021-03-30</td>\n","      <td>2105</td>\n","      <td>91976</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>2021-03-31</td>\n","      <td>2147</td>\n","      <td>82231</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>2021-04-01</td>\n","      <td>101</td>\n","      <td>1519</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>91 rows × 3 columns</p>\n","</div>"],"text/plain":["         Date  Post_Count  Total_Comments\n","0  2021-01-01         589           45186\n","1  2021-01-02         625           11609\n","2  2021-01-03         613           25134\n","3  2021-01-04        1029           55169\n","4  2021-01-05         965           65804\n","..        ...         ...             ...\n","86 2021-03-28        1178           30131\n","87 2021-03-29        2065           85797\n","88 2021-03-30        2105           91976\n","89 2021-03-31        2147           82231\n","90 2021-04-01         101            1519\n","\n","[91 rows x 3 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["df_all_reddit_data.rename(columns={'created_at': 'Date'}, inplace=True)\n","df_grouped = df_all_reddit_data.groupby('Date')\n","\n","df_grouped = df_all_reddit_data.groupby('Date').size().reset_index(name='Post_Count')\n","\n","df_comments_count = df_all_reddit_data.groupby('Date')['num_comments'].sum().reset_index(name='Total_Comments')\n","\n","# Merge 'df_grouped' with 'df_comments_count' on 'Date'\n","df_grouped = df_grouped.merge(df_comments_count, on='Date', how='left')\n","\n","df_grouped\n","\n","\n","# Now, you can perform operations on each group\n","# For example, you can calculate the sum of 'score' and 'num_comments' for each date\n","#result = df_grouped[['score', 'num_comments']].sum()\n","\n","# The result DataFrame will have 'created_at' date as the index and sum of 'score' and 'num_comments' for each date\n","#print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Post_Count</th>\n","      <th>Total_Comments</th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-01-01</td>\n","      <td>589</td>\n","      <td>45186</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-01-02</td>\n","      <td>625</td>\n","      <td>11609</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-01-03</td>\n","      <td>613</td>\n","      <td>25134</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-01-04</td>\n","      <td>1029</td>\n","      <td>55169</td>\n","      <td>19.00</td>\n","      <td>19.1000</td>\n","      <td>17.1500</td>\n","      <td>17.25</td>\n","      <td>10022474.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-01-05</td>\n","      <td>965</td>\n","      <td>65804</td>\n","      <td>17.35</td>\n","      <td>18.0765</td>\n","      <td>17.2300</td>\n","      <td>17.37</td>\n","      <td>4961457.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>2021-03-28</td>\n","      <td>1178</td>\n","      <td>30131</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>2021-03-29</td>\n","      <td>2065</td>\n","      <td>85797</td>\n","      <td>180.75</td>\n","      <td>193.9200</td>\n","      <td>173.5100</td>\n","      <td>181.30</td>\n","      <td>10042175.0</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>2021-03-30</td>\n","      <td>2105</td>\n","      <td>91976</td>\n","      <td>187.50</td>\n","      <td>204.3000</td>\n","      <td>182.0000</td>\n","      <td>194.46</td>\n","      <td>17094924.0</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>2021-03-31</td>\n","      <td>2147</td>\n","      <td>82231</td>\n","      <td>197.50</td>\n","      <td>199.4600</td>\n","      <td>187.1102</td>\n","      <td>189.82</td>\n","      <td>8393834.0</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>2021-04-01</td>\n","      <td>101</td>\n","      <td>1519</td>\n","      <td>193.36</td>\n","      <td>196.9690</td>\n","      <td>183.6000</td>\n","      <td>191.45</td>\n","      <td>9334345.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>91 rows × 8 columns</p>\n","</div>"],"text/plain":["         Date  Post_Count  Total_Comments    Open      High       Low   Close  \\\n","0  2021-01-01         589           45186     NaN       NaN       NaN     NaN   \n","1  2021-01-02         625           11609     NaN       NaN       NaN     NaN   \n","2  2021-01-03         613           25134     NaN       NaN       NaN     NaN   \n","3  2021-01-04        1029           55169   19.00   19.1000   17.1500   17.25   \n","4  2021-01-05         965           65804   17.35   18.0765   17.2300   17.37   \n","..        ...         ...             ...     ...       ...       ...     ...   \n","86 2021-03-28        1178           30131     NaN       NaN       NaN     NaN   \n","87 2021-03-29        2065           85797  180.75  193.9200  173.5100  181.30   \n","88 2021-03-30        2105           91976  187.50  204.3000  182.0000  194.46   \n","89 2021-03-31        2147           82231  197.50  199.4600  187.1102  189.82   \n","90 2021-04-01         101            1519  193.36  196.9690  183.6000  191.45   \n","\n","        Volume  \n","0          NaN  \n","1          NaN  \n","2          NaN  \n","3   10022474.0  \n","4    4961457.0  \n","..         ...  \n","86         NaN  \n","87  10042175.0  \n","88  17094924.0  \n","89   8393834.0  \n","90   9334345.0  \n","\n","[91 rows x 8 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["merged_df = df_grouped.merge(gme_jan_apr2021_df, on='Date', how='outer')\n","merged_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Post_Count</th>\n","      <th>Total_Comments</th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-01-04</td>\n","      <td>1029</td>\n","      <td>55169</td>\n","      <td>19.00</td>\n","      <td>19.1000</td>\n","      <td>17.1500</td>\n","      <td>17.25</td>\n","      <td>10022474</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-01-05</td>\n","      <td>965</td>\n","      <td>65804</td>\n","      <td>17.35</td>\n","      <td>18.0765</td>\n","      <td>17.2300</td>\n","      <td>17.37</td>\n","      <td>4961457</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2021-01-06</td>\n","      <td>1225</td>\n","      <td>77419</td>\n","      <td>17.34</td>\n","      <td>18.9800</td>\n","      <td>17.3300</td>\n","      <td>18.36</td>\n","      <td>6056248</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2021-01-07</td>\n","      <td>1399</td>\n","      <td>68127</td>\n","      <td>18.47</td>\n","      <td>19.4500</td>\n","      <td>18.0200</td>\n","      <td>18.08</td>\n","      <td>6129276</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2021-01-08</td>\n","      <td>1551</td>\n","      <td>95624</td>\n","      <td>18.18</td>\n","      <td>18.3000</td>\n","      <td>17.0800</td>\n","      <td>17.69</td>\n","      <td>6481960</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>2021-03-25</td>\n","      <td>3493</td>\n","      <td>146707</td>\n","      <td>123.49</td>\n","      <td>187.5000</td>\n","      <td>116.9000</td>\n","      <td>183.75</td>\n","      <td>49926442</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>2021-03-26</td>\n","      <td>2986</td>\n","      <td>148208</td>\n","      <td>197.68</td>\n","      <td>218.9344</td>\n","      <td>163.2600</td>\n","      <td>181.00</td>\n","      <td>37430672</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>2021-03-29</td>\n","      <td>2065</td>\n","      <td>85797</td>\n","      <td>180.75</td>\n","      <td>193.9200</td>\n","      <td>173.5100</td>\n","      <td>181.30</td>\n","      <td>10042175</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>2021-03-30</td>\n","      <td>2105</td>\n","      <td>91976</td>\n","      <td>187.50</td>\n","      <td>204.3000</td>\n","      <td>182.0000</td>\n","      <td>194.46</td>\n","      <td>17094924</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>2021-03-31</td>\n","      <td>2147</td>\n","      <td>82231</td>\n","      <td>197.50</td>\n","      <td>199.4600</td>\n","      <td>187.1102</td>\n","      <td>189.82</td>\n","      <td>8393834</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>61 rows × 8 columns</p>\n","</div>"],"text/plain":["         Date  Post_Count  Total_Comments    Open      High       Low   Close  \\\n","3  2021-01-04        1029           55169   19.00   19.1000   17.1500   17.25   \n","4  2021-01-05         965           65804   17.35   18.0765   17.2300   17.37   \n","5  2021-01-06        1225           77419   17.34   18.9800   17.3300   18.36   \n","6  2021-01-07        1399           68127   18.47   19.4500   18.0200   18.08   \n","7  2021-01-08        1551           95624   18.18   18.3000   17.0800   17.69   \n","..        ...         ...             ...     ...       ...       ...     ...   \n","83 2021-03-25        3493          146707  123.49  187.5000  116.9000  183.75   \n","84 2021-03-26        2986          148208  197.68  218.9344  163.2600  181.00   \n","87 2021-03-29        2065           85797  180.75  193.9200  173.5100  181.30   \n","88 2021-03-30        2105           91976  187.50  204.3000  182.0000  194.46   \n","89 2021-03-31        2147           82231  197.50  199.4600  187.1102  189.82   \n","\n","      Volume  \n","3   10022474  \n","4    4961457  \n","5    6056248  \n","6    6129276  \n","7    6481960  \n","..       ...  \n","83  49926442  \n","84  37430672  \n","87  10042175  \n","88  17094924  \n","89   8393834  \n","\n","[61 rows x 8 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["cleaned_df = merged_df.dropna().copy()\n","cleaned_df['Volume'] = cleaned_df['Volume'].astype(int)\n","# Remove the last row using .iloc\n","cleaned_df = cleaned_df.iloc[:-1]\n","cleaned_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["166996"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["cleaned_df['Post_Count'].max()"]},{"cell_type":"markdown","metadata":{},"source":["# This is the plot\n","### Maybe animate it"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["'c:\\\\Users\\\\annaj\\\\Desktop\\\\DS105\\\\ds105a-project-data-dabblers\\\\docs\\\\interactive_plot.html'"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["from bokeh.plotting import figure, show, output_file, save\n","from bokeh.models import ColumnDataSource, LinearColorMapper, ColorBar, NumeralTickFormatter, Title, LinearAxis\n","from bokeh.transform import transform\n","from bokeh.models.tools import HoverTool\n","from bokeh.models import Range1d  # Import Range1d for secondary y-axis\n","import pandas as pd\n","\n","# Ensure your dataframe is sorted by date if it's not already\n","cleaned_df['Date'] = pd.to_datetime(cleaned_df['Date'])\n","cleaned_df.sort_values('Date', inplace=True)\n","\n","# Create a ColumnDataSource from the dataframe\n","source = ColumnDataSource(cleaned_df)\n","\n","# Create a color mapper for total comments with a color bar\n","color_mapper = LinearColorMapper(palette=\"Viridis256\", low=cleaned_df['Total_Comments'].min(), high=cleaned_df['Total_Comments'].max())\n","\n","# Define a size mapping based on 'Post_Count', here we scale the 'Post_Count' values to a range of 6 to 30\n","# Adjust this scaling factor to suit the size of your plot or preference\n","scale_factor = 0.0015  # This is a scaling factor for the size\n","max_size = 10000\n","min_size = 5\n","cleaned_df['size'] = cleaned_df['Post_Count'] * scale_factor\n","cleaned_df['size'] = cleaned_df['size'].clip(lower=min_size, upper=max_size)\n","\n","# Update the source with the new size data\n","source.data['size'] = cleaned_df['size']\n","\n","# Create a figure object\n","p = figure(width=1450, height=700, x_axis_type=\"datetime\")\n","\n","# Create a title and customize its properties\n","title = Title(text=\"GameStop Trading Frenzy: A Synchronized Surge in Stock Price, Volume, and Online Buzz\", text_font_size=\"16pt\", align=\"center\")\n","\n","# Add circle glyphs to the figure\n","p.circle(x='Date', y='Volume', size='size', source=source, color=transform('Total_Comments', color_mapper), alpha=0.7)\n","\n","# Add a color bar to the right of the plot\n","color_bar = ColorBar(color_mapper=color_mapper, label_standoff=12, location=(0,0), title='Total Comments', formatter=NumeralTickFormatter(format=\"0,0\"))\n","p.add_layout(color_bar, 'below')\n","\n","# Customize the plot\n","p.yaxis.formatter = NumeralTickFormatter(format=\"0a\")\n","p.xaxis.axis_label = 'Date'\n","p.yaxis.axis_label = 'Trading Volume (in millions)'\n","\n","# Specify the range for the secondary y-axis (right side)\n","p.extra_y_ranges = {'Close Price': Range1d(start=cleaned_df['Close'].min(), end=400)}\n","\n","# Add the secondary y-axis (right side) for Close Price\n","p.line('Date', 'Close', source=source, color='red', y_range_name='Close Price', legend_label='Close Price')\n","p.add_layout(LinearAxis(y_range_name='Close Price', axis_label='Close Price'), 'right')\n","\n","# Add hover tool\n","hover = HoverTool(tooltips=[(\"Date\", \"@Date{%F}\"),\n","                            (\"Volume\", \"@Volume\"),\n","                            (\"Post Count\", \"@Post_Count\"),\n","                            (\"Total Comments\", \"@Total_Comments\"),\n","                            (\"Close Price\", \"@Close\")],\n","                  formatters={'@Date': 'datetime'})\n","p.add_tools(hover)\n","\n","# Set the title\n","p.title = title\n","\n","# Saving the plot to the visualisations and docs folders\n","output_file(\"interactive_plot.html\")\n","output_file(\"../docs/interactive_plot.html\")\n","save(p)\n"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
