{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import json\n","import requests\n","\n","import pandas as pd\n","import mplfinance as mpf\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["os.makedirs(\"data\", exist_ok=True)\n","os.makedirs(\"visualisations\", exist_ok=True)"]},{"cell_type":"markdown","metadata":{},"source":["Scraping daily data"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# File path for the JSON data\n","file_path = \"data/gme_daily_data.json\"\n","\n","# Check if the file already exists\n","if not os.path.exists(file_path):\n","    # Fetch the data only if the file does not exist\n","    url = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=GME&outputsize=full&apikey=71F522PIQRFAFZZO'\n","    response = requests.get(url)\n","    gme_daily_data = response.json()\n","\n","    # Save the data to a JSON file\n","    with open(file_path, \"w\") as file:\n","        json.dump(gme_daily_data, file)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["Date      object\n","Open      object\n","High      object\n","Low       object\n","Close     object\n","Volume    object\n","dtype: object"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Reading the JSON file\n","gme_daily_data_df = pd.read_json('data/gme_daily_data.json')\n","\n","# Extracting the relevant time series data\n","time_series_daily_data = gme_daily_data_df['Time Series (Daily)'].dropna().to_dict()\n","\n","# Creating a new DataFrame with the structured data\n","gme_daily_transformed_df = pd.DataFrame.from_dict(time_series_daily_data, orient='index')\n","gme_daily_transformed_df.reset_index(inplace=True)\n","gme_daily_transformed_df.rename(columns={'index': 'Date', '1. open': 'Open', '2. high': 'High', '3. low': 'Low', '4. close': 'Close', '5. volume': 'Volume'}, inplace=True)\n","gme_daily_transformed_df_sorted = gme_daily_transformed_df.sort_index()\n","\n","# Displaying the first few rows of the transformed DataFrame\n","gme_daily_transformed_df_sorted.head()\n","gme_daily_transformed_df_sorted.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["Changing datatypes"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2024-02-05</td>\n","      <td>14.50</td>\n","      <td>14.61</td>\n","      <td>13.40</td>\n","      <td>13.46</td>\n","      <td>4361519.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2024-02-02</td>\n","      <td>14.15</td>\n","      <td>14.92</td>\n","      <td>14.08</td>\n","      <td>14.73</td>\n","      <td>2924462.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2024-02-01</td>\n","      <td>14.34</td>\n","      <td>14.42</td>\n","      <td>14.02</td>\n","      <td>14.42</td>\n","      <td>2220154.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2024-01-31</td>\n","      <td>14.40</td>\n","      <td>14.83</td>\n","      <td>14.22</td>\n","      <td>14.23</td>\n","      <td>2684680.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2024-01-30</td>\n","      <td>14.54</td>\n","      <td>14.82</td>\n","      <td>14.51</td>\n","      <td>14.55</td>\n","      <td>1652561.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Date   Open   High    Low  Close     Volume\n","0 2024-02-05  14.50  14.61  13.40  13.46  4361519.0\n","1 2024-02-02  14.15  14.92  14.08  14.73  2924462.0\n","2 2024-02-01  14.34  14.42  14.02  14.42  2220154.0\n","3 2024-01-31  14.40  14.83  14.22  14.23  2684680.0\n","4 2024-01-30  14.54  14.82  14.51  14.55  1652561.0"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["gme_daily_transformed_df = gme_daily_transformed_df.astype({\n","    'Date': 'datetime64[ns]',\n","    'Open': 'float',\n","    'High': 'float',\n","    'Low': 'float',\n","    'Close': 'float',\n","    'Volume': 'float'\n","})\n","\n","gme_daily_transformed_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["Pickling the Dataframe to be used across Jupyter notebooks"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"OSError","evalue":"Cannot save file into a non-existent directory: 'scraping'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pickle the DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m gme_daily_transformed_df\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscraping/gme_daily_transformed_df.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3085\u001b[0m, in \u001b[0;36mNDFrame.to_pickle\u001b[0;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3034\u001b[0m \u001b[38;5;124;03mPickle (serialize) object to file.\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m   3082\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_pickle\n\u001b[0;32m-> 3085\u001b[0m to_pickle(\n\u001b[1;32m   3086\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3087\u001b[0m     path,\n\u001b[1;32m   3088\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   3089\u001b[0m     protocol\u001b[38;5;241m=\u001b[39mprotocol,\n\u001b[1;32m   3090\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   3091\u001b[0m )\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/pickle.py:105\u001b[0m, in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    103\u001b[0m     protocol \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    106\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    109\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    111\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# letting pickle write directly to the buffer is more memory-efficient\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(obj, handles\u001b[38;5;241m.\u001b[39mhandle, protocol\u001b[38;5;241m=\u001b[39mprotocol)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 739\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'scraping'"]}],"source":["# Pickle the DataFrame\n","gme_daily_transformed_df.to_pickle(\"scraping/gme_daily_transformed_df.pkl\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Plotting a Candlestick Chart of GME Stock Price during the Gamestop short squeeze"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filtering the DataFrame to include only data from December 2020 to April 2021 and creating a copy\n","gme_jan_apr2021_df = gme_daily_transformed_df[(gme_daily_transformed_df['Date'] >= '2021-01-01') & (gme_daily_transformed_df['Date'] <= '2021-04-30')].copy()\n","\n","# Ensure 'Date' is the index\n","gme_jan_apr2021_df.set_index('Date', inplace=True)\n","\n","# Sorting the DataFrame by 'Date' in ascending order\n","gme_jan_apr2021_df.sort_index(inplace=True)\n","\n","# Plotting the OHLC candlestick chart\n","mpf.plot(gme_jan_apr2021_df, \n","         type='candle', \n","         style='yahoo', \n","         volume=True, \n","         #tight_layout=True,\n","         datetime_format='%b %d, %Y',\n","         xrotation=45,\n","         title='GME Stock Price (Jan 2021-Apr 2021)',\n","         savefig='visualisations/gme_stock_price_candlestick_chart.png')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
