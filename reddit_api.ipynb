{"cells":[{"cell_type":"code","execution_count":148,"metadata":{},"outputs":[],"source":["import os\n","import json\n","import requests\n","import requests.auth\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import time\n","import datetime\n","\n","from pprint import pprint\n","from scrapy import Selector\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["Reading the Reddit credentials from the json file in gitignore to prevent sensitive information being exposed on GitHub."]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[],"source":["credentials_file_path = \"../credentials.json\"\n","\n","# open the file and load the data into a variable\n","with open(credentials_file_path, \"r\") as f:\n","    credentials = json.load(f)"]},{"cell_type":"markdown","metadata":{},"source":["Obtainng a token\n","- Setting up credentials\n","- Sending the request"]},{"cell_type":"code","execution_count":150,"metadata":{},"outputs":[],"source":["# We will still use the requests library, only this time we have to set up authentication parameters first\n","client_auth = requests.auth.HTTPBasicAuth(credentials[\"app_client_id\"], credentials[\"app_client_secret\"])\n","\n","# You also need to send, via HTTP POST, your Reddit username and password.\n","post_data = {\"grant_type\": \"password\", \"username\": credentials[\"reddit_username\"], \"password\": credentials[\"reddit_password\"]}\n","\n","# Just like Wikimedia, Reddit API also requests that we self-identify ourselves in the User-Agent.\n","headers = {\"User-Agent\": f\"LSE DS105A API practice by {credentials['reddit_username']}\"}\n"]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[{"data":{"text/plain":["{'access_token': 'eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNzAxNzM1MDQ5LjUzNzMxNiwiaWF0IjoxNzAxNjQ4NjQ5LjUzNzMxNiwianRpIjoiLXJWWjlsNWNxUDJvWDJtU0tqSXl2NE0xcjJJTkJ3IiwiY2lkIjoiRkpCaWJYZGppdjRZTFlSdlpibFZBQSIsImxpZCI6InQyX29xeTIwYjRuZiIsImFpZCI6InQyX29xeTIwYjRuZiIsImxjYSI6MTcwMTA2NDAxMzQ5Nywic2NwIjoiZUp5S1Z0SlNpZ1VFQUFEX193TnpBU2MiLCJmbG8iOjl9.MMToo8afWS1Fy77xYYX0tVA_PaUx9oLR1Xzj3nPJH6J3FLkIcKW0AvhcuaoA_p9ciAler0GuxTzflHhMjkQMyRGwZEFWvvFLDxbGzPLtQXv6bbkN09mFgiFI77CBG-DhMH_UWbeCy3Fo63nHl6INxZOaPWa9eO-kxcowNlYWML85wFMZTe_3hzpBkgBybW8Evf4X1n91r2_3_-IoxZPYIGkTAAUr-FqoHaViXvvTY5zQOgMJFkIcsJ_UdvPrCSiGPrB5xzvlz34YaWPJH6b7QOXGIZcPvWOMYTTc0xZlO9ANtvqQqSeGKqBRd88GosJs1cUd2l_m5JRaoqWZDC5wCA',\n"," 'token_type': 'bearer',\n"," 'expires_in': 86400,\n"," 'scope': '*'}"]},"execution_count":151,"metadata":{},"output_type":"execute_result"}],"source":["# From their documentation, I learned this is the endpoint I need\n","ACCESS_TOKEN_ENDPOINT = \"https://www.reddit.com/api/v1/access_token\"\n","\n","# This time we are sending a HTTP POST instead of a HTTP GET\n","response = requests.post(ACCESS_TOKEN_ENDPOINT, auth=client_auth, data=post_data, headers=headers)\n","response.json()"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[],"source":["#Setup/authentification, and defining subreddit\n","access_token = response.json()['access_token']\n","\n","headers = {\n","    \"Authorization\": f\"bearer {access_token}\",\n","    \"User-Agent\": \"LSE DS105A API practice by yourusername\"\n","}\n","\n","subreddit = 'wallstreetbets'\n","url = f'https://oauth.reddit.com/r/{subreddit}/'"]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[],"source":["import requests\n","import time\n","import datetime\n","import pandas as pd\n","\n","# Setup/authentication, and defining subreddit\n","access_token = response.json()['access_token']\n","headers = {\n","    \"Authorization\": f\"bearer {access_token}\",\n","    \"User-Agent\": \"LSE DS105A API practice by yourusername\"\n","}\n","subreddit = 'wallstreetbets'\n","\n","# The Reddit API only allows you to fetch 100 posts at a time\n","url = f'https://oauth.reddit.com/r/{subreddit}/new'\n","params = {\n","    'limit': 100,\n","    'after': None  # Initialize 'after' with None for the first request\n","}\n","\n","all_posts = []\n","\n","while True:\n","    response = requests.get(url, headers=headers, params=params)\n","    response_data = response.json()\n","    posts = response_data.get('data', {}).get('children', [])\n","    \n","    if not posts:\n","        break  # Break the loop if no more posts are found\n","    \n","    for post in posts:\n","        post_data = post.get('data', {})\n","        all_posts.append({\n","            'title': post_data.get('title'),\n","            'score': post_data.get('score'),\n","            'id': post_data.get('id'),\n","            'created': post_data.get('created_utc'),\n","            'comments_num': post_data.get('num_comments'),\n","            'upvote_ratio': post_data.get('upvote_ratio'),\n","            'content': post_data.get('selftext')\n","            # Add any other fields you need\n","        })\n","    \n","    # Set the 'after' parameter to the ID of the last post in the batch for pagination\n","    last_post_id = posts[-1].get('data', {}).get('id')\n","    params['after'] = f't3_{last_post_id}'\n","    \n","    time.sleep(1)  # Sleep for a short time to respect rate limits\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(all_posts)\n","\n","# Convert the 'created' column to datetime format\n","df['created_datetime'] = pd.to_datetime(df['created'], unit='s')"]},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>score</th>\n","      <th>id</th>\n","      <th>created</th>\n","      <th>comments_num</th>\n","      <th>upvote_ratio</th>\n","      <th>content</th>\n","      <th>created_datetime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>868</th>\n","      <td>How do you buy calls on interests rate</td>\n","      <td>0</td>\n","      <td>17wxzwm</td>\n","      <td>1.700170e+09</td>\n","      <td>10</td>\n","      <td>0.33</td>\n","      <td>What if we make a an etf on that and keep buyi...</td>\n","      <td>2023-11-16 21:29:24</td>\n","    </tr>\n","    <tr>\n","      <th>869</th>\n","      <td>Dude! Is this guy for real? Let’s go $BJ. Earn...</td>\n","      <td>31</td>\n","      <td>17wxon3</td>\n","      <td>1.700169e+09</td>\n","      <td>14</td>\n","      <td>0.86</td>\n","      <td></td>\n","      <td>2023-11-16 21:16:31</td>\n","    </tr>\n","    <tr>\n","      <th>870</th>\n","      <td>good month</td>\n","      <td>18</td>\n","      <td>17wxn0o</td>\n","      <td>1.700169e+09</td>\n","      <td>14</td>\n","      <td>0.88</td>\n","      <td>20k by xmas</td>\n","      <td>2023-11-16 21:14:35</td>\n","    </tr>\n","    <tr>\n","      <th>871</th>\n","      <td>What Are Your Moves Tomorrow, November 17, 2023</td>\n","      <td>77</td>\n","      <td>17wxb1n</td>\n","      <td>1.700168e+09</td>\n","      <td>4203</td>\n","      <td>0.92</td>\n","      <td>Make sure you're in the [WSB Discord](https://...</td>\n","      <td>2023-11-16 21:00:37</td>\n","    </tr>\n","    <tr>\n","      <th>872</th>\n","      <td>The tale of Solomon “Sage” Grunder (born on a ...</td>\n","      <td>1</td>\n","      <td>17wx78p</td>\n","      <td>1.700168e+09</td>\n","      <td>2</td>\n","      <td>0.54</td>\n","      <td>In the canyon of towering screens and ticking ...</td>\n","      <td>2023-11-16 20:55:44</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 title  score       id  \\\n","868             How do you buy calls on interests rate      0  17wxzwm   \n","869  Dude! Is this guy for real? Let’s go $BJ. Earn...     31  17wxon3   \n","870                                         good month     18  17wxn0o   \n","871    What Are Your Moves Tomorrow, November 17, 2023     77  17wxb1n   \n","872  The tale of Solomon “Sage” Grunder (born on a ...      1  17wx78p   \n","\n","          created  comments_num  upvote_ratio  \\\n","868  1.700170e+09            10          0.33   \n","869  1.700169e+09            14          0.86   \n","870  1.700169e+09            14          0.88   \n","871  1.700168e+09          4203          0.92   \n","872  1.700168e+09             2          0.54   \n","\n","                                               content    created_datetime  \n","868  What if we make a an etf on that and keep buyi... 2023-11-16 21:29:24  \n","869                                                    2023-11-16 21:16:31  \n","870                                        20k by xmas 2023-11-16 21:14:35  \n","871  Make sure you're in the [WSB Discord](https://... 2023-11-16 21:00:37  \n","872  In the canyon of towering screens and ticking ... 2023-11-16 20:55:44  "]},"execution_count":154,"metadata":{},"output_type":"execute_result"}],"source":["df.tail()"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
